---
description: downloading grib files, wave forecast wind forecast data
globs: *.py
---
# how to download grib files for wind and wave forecasts

## Wave Forecast Processing Rules
wave forecast is processed through /waves/v2/[station_id]
- endpoint in [wave_routes_v2.py](mdc:features/waves/routes/wave_routes_v2.py) 
- service is [wave_data_service_v2.py](mdc:features/waves/services/wave_data_service_v2.py)
- client to download files is [gfs_wave_client.py](mdc:features/waves/services/gfs_wave_client.py)
- [wave_routes.py](mdc:features/waves/routes/wave_routes.py) [wave_data_service.py](mdc:features/waves/services/wave_data_service.py) is DEPRECATED
- refer to [config.py](mdc:core/config.py) – keep this updated
   -- TO DO: this needs to be organized into wind, wave config
- use types everywhere [wave_types.py](mdc:features/waves/models/wave_types.py) e.g avoid passing around objects, and dicts.

## types 
- wave forecast types are in [wave_types.py](mdc:features/waves/models/wave_types.py)
- station [station_types.py](mdc:features/common/models/station_types.py), use `Station` everywhere, not objects

## url structure

### base url
downloads using grib filter to customize variables, subregion and more. 
```https://nomads.ncep.noaa.gov/cgi-bin/filter_gfswave.pl```

### complete url 
```https://nomads.ncep.noaa.gov/cgi-bin/filter_gfswave.pl?file=gfswave.t18z.atlocn.0p16.f000.grib2&lev_surface=on&var_DIRPW=on&var_HTSGW=on&var_PERPW=on```

## Data Structure

### GRIB Variables
- `swh`: Significant wave height [meters, ≥ 0]
- `perpw`: Peak wave period [seconds, ≥ 0]
- `dirpw`: Primary wave direction [degrees true, 0-360]

### Coordinate System
- Longitude: 0-360° system (convert from -180/180)
- Latitude: -90° to 90° (unchanged)
- Time: UTC timestamps from `valid_time` field

## Date and time handling 

	•	UTC-Based Time:
Ensure all calculations use UTC since GFS model run times (00, 06, 12, 18) are based on UTC. Local time zones must be converted properly or the system clock should be set to UTC for consistency.
	•	Cycle Times and Run Availability:
GFS model runs are scheduled at fixed intervals. Your logic should select the latest run (e.g., 12z if it’s past 12 UTC) and fall back to a previous cycle if the current run’s data is not yet available.
	•	Latency Window:
Incorporate a latency (e.g., 2 hours) to account for data processing delays. This ensures you only request data from runs that have had enough time to be published.
	•	Edge Cases (Day Transitions):
When the current UTC hour is before the earliest model run for the day, your logic should correctly fetch the previous day’s latest run (usually 18z).
	•	Local vs. Production Environment:
For local testing, verify that your system clock is accurate. In production, consider environment variables to adjust latency or cycle run preferences, and use a reliable time source.
